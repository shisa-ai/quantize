These are all our scripts for quantizing models

## Mistral-Nemo-Japanese-Instruct-2408
Simple single-GPU quantization to W8A8 (best quality/speed), FP8, W4A16
