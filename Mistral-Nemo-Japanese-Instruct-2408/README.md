See for original checkins: https://github.com/shisa-ai/benchmarks/tree/main/g5-vllm-vs-sglang

llmcompressor:
- FP8 Dynamic

GPTQModel
- W4A16 g32, g32-noact, g128

ExLlamaV2
- EXL2

MLC
